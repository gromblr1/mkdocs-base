[Online Regex tester & debugger](https://regex101.com/)  
[DuckDuckGo regex cheat sheet](https://duckduckgo.com/?q=regex+cheat+sheet&ia=cheatsheet&iax=1)  
[Regex tutorial — A quick cheatsheet by examples](https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285)  
[REGEXTester](https://www.regextester.com/)  <-- allows saving of REGEX scripts  
[REGEXr.com](https://regexr.com/)  <-- RegExr is an online tool to learn, build, & test Regular Expressions 
[Rubular.com](https://rubular.com/)  

[SQLFiddle.com](http://sqlfiddle.com/)  
[Refiddle.com](http://refiddle.com/)  <-- color-coded regex editor !  ([Skynet mirror](https://siasky.net/fAZQF5cTbNr_JZD2vClz3IowODGRclYt2L3z2qieLB1NzA/?))  
[REGEXOne.com](https://regexone.com/)  <-- Learn Regular Expressions with simple, interactive exercises.
[SQLBolt.com](https://sqlbolt.com)  

# 1. REGEX how to find specific URLS
After copying webpage code (html etc) to the first box with [Regex Tester and generator](https://www.beautifyconverter.com/regex-tester.php) ,  use REGEX expression below to find "https://i.4pcdn.org/pol/" URL's.  
**https?:\/\/i\.4pcdn\.org\/pol\/..................** 

## 1.5 (optional) remove entire URL except for the file name
This is useful if you need any files such as pictures to be locally referred instead of pointing to the external source.  
Using [Regex Tester and generator](https://www.beautifyconverter.com/regex-tester.php) in the "Replace" field, leave it blank and click replace.  

## 2. (optional)Removing duplicate URL's in text document
[Text Mechanic: Remove Duplicate Lines](https://textmechanic.com/text-tools/basic-text-tools/remove-duplicate-lines/)  
After this, copy/paste and save into a text document called url_list.txt.
### 3. use wget
**wget -i url_list.txt**  
^^ This will download all the files in the document.  

#WGET
[Downloading files with wget](https://www.pair.com/support/kb/paircloud-downloading-files-with-wget/)  
[Linux wget command](https://www.computerhope.com/unix/wget.htm)  
[How to make an offline mirror copy of a website with wget](https://alvinalexander.com/linux-unix/how-to-make-offline-mirror-copy-website-with-wget/)  

# Localhost tunneling
[Staqlab-tunnel](https://tunnel.staqlab.com/)  <-- offers free permanent subdomain  (w/ugly splash page)  
[NGROK](https://ngrok.com/)  <-- awesome but subdomains expire and are randomly generated  

# DNS Tools
[DNS-O-Matic](https://www.dnsomatic.com/)  <-- free/easy way to announce your dynamic IP changes to MANY services w/ a single update.  

# URL TOOLS
[URL Extractor For Web Pages and Text](http://www.convertcsv.com/url-extractor.htm)  
[FREE URL EXTRACTOR](https://bulkdachecker.com/url-extractor/)  
[Online Text to Link Converter](https://www.htmlstrip.com/text-to-link-converter)  <-- convert list of URLS into clickable links  

[4url.cc: URL shortener](https://4url.cc/)  
[URLTeam: URL_shorteners](https://archiveteam.org/?title=URLTeam#URL_shorteners)  

# Website extensional tools
[Search HackerNews](https://hn.algolia.com/)  <-- extremely handly search engine to look through HackerNews  

#WEB SCRAPING
[SimpleScraper.io](https://simplescraper.io/)  <-- Extract data from any website in seconds  
[Webscraper.io](https://webscraper.io/)  <-- Making web data extraction easy and accessible for everyone  

## Other web tools/tips
[Tinyapps.org](https://tinyapps.org/network.html) <-- an aging catalog of tiny, well-made software primarily for Windows.      
[Parsero](https://tools.kali.org/information-gathering/parsero)  <-- free script written in Python which reads the Robots.txt file of a web server and looks at the Disallow entries.  
[CutyCapt](http://cutycapt.sourceforge.net/)  <-- CutyCapt is a small cross-platform command-line utility to capture WebKit's rendering of a web page into a variety of vector and bitmap formats  
[WhatWeb](https://tools.kali.org/web-applications/whatweb)  <-- When you visit a website in your browser, the transaction includes many hints of what web technologies are powering that website  

[Penetration Testing Tools](https://en.kali.tools/)  ((en.kali.tools))  
[Kali Linux Tools Listing](https://tools.kali.org/tools-listing)  ((tools.kali.org))  

[.htaccess Snippets](https://github.com/phanan/htaccess)  
[.htaccess Generator](https://www.htaccessredirect.net/)  
# No-code platforms
[Appgyver](https://www.appgyver.com/)  <--The world's first professional no-code platform, enabling you to build apps for all form factors, including mobile, desktop, browser, TV and others.  
[Bubble.io](https://bubble.io/)  <-- enables anyone to design, develop, and launch powerful web apps without writing code.  

## Other
[Vocaroo](https://vocaroo.com/)  
[What happens when you load a URL?](https://danluu.com/navigate-url/)  ((danluu.com))  
[Aesthetic text generator](https://exoticfonts.com/aesthetic-text/)  
[Rotten Websites](https://rottenwebsites.miraheze.org/wiki/Category:Websites)  
[Hitchwiki: The Guide to Hitchhiking the World!](https://hitchwiki.org/en/Main_Page)  

#IRC
[EFNET General Questions](http://www.efnet.org/?module=docs&doc=24)  ((efnet.org))  
[ADIIRC Commands](https://dev.adiirc.com/projects/adiirc/wiki/Scripting_Commands)  ((adiirc.com))  
[ADIIRC Nick Colors Options](https://dev.adiirc.com/projects/adiirc/wiki/Nick_Colors_Options)  ((adiirc.com))  
[KIWIIRC Commands](https://kiwiirc.com/docs/client/commands)  ((kiwiirc.com))  
[IRC Client step-by-step guides](https://confluence.fuelrats.com/display/public/FRKB/IRC+Client+Setup+Guides)  ((fuelrats.com))  

# IRC Tools
[Freenode: Nickname Registration](https://freenode.net/kb/answer/registration) ((freenode.net))  


#tech
[Locoloader](https://www.locoloader.com/)   <-- tool used for downloading bandcamp mp3's
[Youtube playlist backup to excel spreadsheets](http://www.williamsportwebdeveloper.com/FavBackUp.aspx)  
[Pandoc: a universal document converter](https://pandoc.org/)  
[Wat Zat Song: Find the name of your songs](https://www.watzatsong.com/en)  <-- Midomi.com & Lyrster.com as well  
[Reddit: Self-Hosted alternatives to popular services](https://www.reddit.com/r/selfhosted/)  
[FreedomBone](https://freedombone.net/)  
[Dark Patterns](https://darkpatterns.org/index.html)  
[KEL CHM Creator](https://dumah7.wordpress.com/2009/02/17/kel-chm-creator-v-1-4-0-0/)  
[Tinc-VPN](https://tinc-vpn.org/)  
[Snopyta.org](https://snopyta.org/)  
[Youtube restriction checker](http://polsy.org.uk/stuff/ytrestrict.cgi)  <-- check which countries a video is restricted  
[Concen.org](https://concen.org/torrents)  
[CachedView.com](https://cachedview.com/)  ((cachedview.com))  <-- look up 404/non-existent CACHED pages from multiple tools  
[Placebear](https://placebear.com/) & [Placekitten](https://placekitten.com/) <-- simple service for getting pictures of bears to use as placeholders in your design/code. Put img size (width & height) after URL  

### tech streaming tools
[Streamable WEB Clipper URL](https://streamable.com/clipper)  <-- clips video (like Youtube ones) w/o downloading them  
[M3U8Player.net](https://m3u8player.net/)  
[Streamwatch.ch](http://streamwat.ch/custom/)  

##tech tools
[fastly Service status](https://status.fastly.com/)  <-- watch for internet outages worldwide  
[The Outages Archives](https://puck.nether.net/pipermail/outages/)  ((puck.nether.net))  
[deadlinkchecker.com](https://www.deadlinkchecker.com/)  <-- check dead links of websites  
[URL Encoder/Decoder](https://www.urlencoder.org/)  <-- use to turn all those symbols in a URL (like %20 for a blank space) into readable format  
[Kutt.it](https://kutt.it/) and [Waa.ai](https://waa.ai/)  <-- URL shorteners   

[Webpage Test](https://www.webpagetest.org/)  <-- Test a website's performance  
[GTMetrix](https://gtmetrix.com/) and [Pingdom tools](https://tools.pingdom.com/)   <-- analyze websites   
[Check-your-website](https://check-your-website.server-daten.de/)  <-- comprehensive DNS tool for your website  
[Lumpysoft](https://lumpysoft.com/) and [Filechef](https://www.filechef.com/) <-- google index hack search  
[MP3Clan](https://mp3clan.com/)  <-- easily hack search to find and download mp3s  
[HTML Beautifier](https://www.10bestdesign.com/dirtymarkup/)  <-- clean up HTML, CSS, JS & API  

#tech communities
[Nixers.net](https://nixers.net/)  
[Blackflag.acid.org](http://blackflag.acid.org/)  
[Reddit:Open Directories](https://www.reddit.com/r/opendirectories/)  

### Virus scanning tools online
[Jotti's malware scan](https://virusscan.jotti.org/en-US/scan-file)  
[Virus total](https://www.virustotal.com/gui/)  <--Analyze suspicious files and URLs to detect types of malware, auto-share them w/the security community  

### webdev
<img src="https://youtube.com/favicon.ico">[Use wget to download / scrape a full website](https://www.youtube.com/watch?v=GJum2O2JM6M&t=418s)  ((youtube.com))   
[Wget](https://en.wikipedia.org/wiki/Wget#Using_Wget)  
[wget Help – commands, usage, flags, examples](https://rehmann.co/blog/wget-help-commands-usage-flags-examples/)  

[DuckDuckGo Instant answers cheat sheet](https://duck.co/ia?repo=goodies&topic=programming)  
[Mirror The Video](https://www.mirrorthevideo.com/)  <-- Flip YouTube videos horizontally. Replace "youtube.com" with "mirrorthevideo.com" in the URL.  

[Conifer](https://conifer.rhizome.org/_faq)  <-- tool to create high-fidelity, interactive captures of any web site you browse and a platform to make those captured websites accessible.  
[Archivebox](https://archivebox.io/)  <-- takes a list of website URLs you want to archive, and creates a local, static, browsable HTML clone of the content from those websites (it saves HTML, JS, media files, PDFs, images and more).  
[Archiving URLs](https://www.gwern.net/Archiving-URLs)  <-- Archiving the Web, because nothing lasts forever: statistics, online archive services, extracting URLs automatically from browsers, and creating a daemon to regularly back up URLs to multiple sources.  
Related: [LinkChecker](https://wummel.github.io/linkchecker/)  <-- checks links in web documents or full websites.   
Related: [Link rot](https://en.wikipedia.org/wiki/Link_rot)  

[Trace.moe](https://trace.moe/about) <-- helps users trace back the original anime by screenshot. It searches over 22300 hours of anime and find the best matching scene. It tells you what anime it is, from which episode and the time that scene appears  
Related: [Multi-service image search](https://iqdb.org/)  
[Extract Lines x to y From a Text File](https://www.browserling.com/tools/extract-lines)  



[Codecanyon.net](https://codecanyon.net/)  <--  Discover 34,468 code scripts and plugins  
### pastebins
[PasteBin](https://pastebin.com/)  
[Bpaste](https://bpa.st/)  
[Paste.rs](https://paste.rs/web)  
[Privatebin.net](https://privatebin.net/)  
[Teknik.io paste](https://paste.teknik.io/)  

###Other 
[Patchbay.pub](https://patchbay.pub/)  
[Take-a-screenshot.org](http://www.take-a-screenshot.org/)  <-- many unknown ways to take screenshots on win/linux/mac/ios/android w/o programs  
[Supportdetails.com](https://supportdetails.com/)  
[CompressPNG.com](https://compresspng.com/)  and [TinyPNG.com](https://tinypng.com/)  

### other interesting tech tidbits
[Top 12 Best Free Video Editing Software for Windows](https://filmora.wondershare.com/video-editor/free-video-editing-software-windows.html)  
[Producthunt.com](https://www.producthunt.com/)  
[tcpdump is amazing](https://jvns.ca/blog/2016/03/16/tcpdump-is-amazing/)  <--learn how to use TCPdump  
[The complete guide to (external) Domain Specific Languages](https://tomassetti.me/domain-specific-languages/)  
[MediaQueri.es](https://mediaqueri.es/)  

# Google tricks
filetype:FILEFORMAT KEYWORD  
intitle:SINGLEKEYWORD <-- will search for a single keyword in title     
allintitle:KEYWORDS  <-- will search multiple keywords in the title    
inurl:SINGLEKEYWORD <-- will search for a single keyword in URL  
allinurl:KEYWORDS  <-- will search multiple keywords in the URL  
link:URL.com <-- will pull up every individual page from that site  

#REGEX 
Match	<font color=green>cat.</font>	
Match	<font color=green>896.</font>	
Match	<font color=green>?=+.</font>	
Skip	abc1  

ANSWER: ...\.  
<hr>
Match	<font color=green>can</font>	 
Match	<font color=green>man</font>	 
Match	<font color=green>fan</font>	 
Skip	dan	 
Skip	ran	 
Skip	pan  

ANSWER: [cmf]an  
ANSWER2: [^drp] <-- an to match any three letter word ending with 'an' that does not start with 'd', 'r' or 'p'.   
<hr>
Match	<font color=green>hog</font>		 
Match	<font color=green>dog</font>		 
Skip	<font color=green>bog</font>	  

ANSWER: [hd]og   
ANSWER2: [^b]og   
<hr>
Match	<font color=green>Ana	</font>	 
Match	<font color=green>Bob	</font>	 
Match	<font color=green>Cpc	</font>	 
Skip	aax	 
Skip	bby	 
Skip	ccz  

ANSWER: [A-C][n-p][a-c]  
<hr>
Match	<font color=green>wazzzzzup	</font>  
Match	<font color=green>wazzzup</font>	 
Skip	wazup  

ANSWER: waz{3,5}up  <-- the numbers in curly braces allow a range of the same character  
<hr>
Match	<font color=green>aaaabcc</font>	 
Match	<font color=green>aabbbbc</font>	 
Match	<font color=green>aacc</font>	
Skip	a  

ANSWER: aa+b*c+  <-- the * allows the previous character to be 0 or more  
ANSWER2: a{2,4}b{0,4}c{1,2}   
<hr>
Match	<font color=green>1 file found?</font>	  
Match	<font color=green>2 files found?</font>	  
Match	<font color=green>24 files found?</font>	  
Skip	No files found.  

ANSWER: \d+ files? found\?  <-- the ? allows the previous character to be optional  